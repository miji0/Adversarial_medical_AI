'''
preprocess0_prepare_binary_dataset.py
--------------------------------------
- ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰
- (ì„ íƒ 1, 2) ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‹¤í–‰ (ë‚˜ë¨¸ì§€ëŠ” ì£¼ì„ì²˜ë¦¬)
    (1) Colab í™˜ê²½ â†’ Google Driveì— ì €ì¥
    (2) ë¡œì»¬ í™˜ê²½ â†’ í˜„ì¬ ë””ë ‰í† ë¦¬ ë‚´ì— processed_data ìƒì„±

** ê¸°ëŠ¥ ìš”ì•½ **
- KaggleHubë¡œ ì›ë³¸ ë°ì´í„°ì…‹(Brain Tumor MRI Dataset) ìë™ ë‹¤ìš´ë¡œë“œ
- ì´ì§„ ë¶„ë¥˜ìš© (tumor / notumor) í´ë” êµ¬ì¡°ë¡œ ì¬ë¶„í• : Notumor(notumor) vs Tumor(glioma, meningioma, pituitary)
- Trainingê³¼ Testing ë°ì´í„° ëª¨ë‘ ì²˜ë¦¬ (ìµœì´ˆ 1íšŒë§Œ ì‹¤í–‰)

** ìƒì„±ë˜ëŠ” í´ë” êµ¬ì¡° **
processed_data/
â”œâ”€ Training/
â”‚   â”œâ”€ notumor/    # ì •ìƒ ë‡Œ MRI ì´ë¯¸ì§€
â”‚   â””â”€ tumor/      # ì¢…ì–‘ ë‡Œ MRI ì´ë¯¸ì§€ (glioma, meningioma, pituitary í†µí•©)
â””â”€ Testing/
    â”œâ”€ notumor/
    â””â”€ tumor/

** ì´ë¯¸ì§€ ê°œìˆ˜ ì •ë³´ (Brain Tumor MRI Dataset) **
- Training: notumor 1595ê°œ, tumor 4117ê°œ
- Testing: notumor 105ê°œ, tumor 906ê°œ
- ì´ ~4,270ê°œ ì´ë¯¸ì§€
'''
import os
import shutil
from pathlib import Path
import sys

def download_kaggle_dataset():
    '''Kaggleì—ì„œ ë‡Œì¢…ì–‘ MRI ë°ì´í„°ì…‹ì„ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ'''
    try:
        import kagglehub
        
        print("[INFO] Kaggle ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        print("[INFO] ë°ì´í„°ì…‹: masoudnickparvar/brain-tumor-mri-dataset")
        
        # ìµœì‹  ë²„ì „ ë‹¤ìš´ë¡œë“œ
        path = kagglehub.dataset_download("masoudnickparvar/brain-tumor-mri-dataset")
        
        print(f"[SUCCESS] ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
        print(f"[INFO] ë‹¤ìš´ë¡œë“œ ê²½ë¡œ: {path}")
        
        # ë‹¤ìš´ë¡œë“œëœ ê²½ë¡œì˜ ì‹¤ì œ êµ¬ì¡° í™•ì¸
        path_obj = Path(path)
        print(f"[INFO] ë‹¤ìš´ë¡œë“œëœ í´ë” ë‚´ìš©:")
        for item in path_obj.iterdir():
            if item.is_dir():
                print(f"  ğŸ“ {item.name}/")
                # í•˜ìœ„ í´ë”ë„ í™•ì¸
                try:
                    for subitem in item.iterdir():
                        if subitem.is_dir():
                            print(f"    ğŸ“ {subitem.name}/")
                        else:
                            print(f"    ğŸ“„ {subitem.name}")
                except PermissionError:
                    print(f"    [ê¶Œí•œ ì˜¤ë¥˜ë¡œ í•˜ìœ„ í´ë” ì ‘ê·¼ ë¶ˆê°€]")
            else:
                print(f"  ğŸ“„ {item.name}")
        
        return path
        
    except ImportError:
        print("[ERROR] kagglehubê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("[INFO] ì„¤ì¹˜ ë°©ë²•: pip install kagglehub")
        return None
    except Exception as e:
        print(f"[ERROR] ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

# ì´ì§„ë¶„ë¥˜ ë°ì´í„°ì…‹ ìƒì„± (notumor vs tumor)
def create_binary_classification_dataset(raw_data_root="raw_data", processed_data_root="processed_data", 
                                       download_from_kaggle=False):
    ''' [ìƒì„±ë˜ëŠ” í´ë” êµ¬ì¡°]
    processed_data/  # ì´ì§„ë¶„ë¥˜ ë°ì´í„° ê²½ë¡œ
    â”œâ”€ Training/
    â”‚   â”œâ”€ notumor/
    â”‚   â””â”€ tumor/
    â””â”€ Testing/
        â”œâ”€ notumor/
        â””â”€ tumor/
    '''
    
    # Kaggleì—ì„œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
    if download_from_kaggle:
        kaggle_path = download_kaggle_dataset()
        if kaggle_path:
            # Kaggleì—ì„œ ë‹¤ìš´ë¡œë“œëœ ê²½ë¡œë¥¼ raw_data_rootë¡œ ì‚¬ìš©
            raw_data_root = kaggle_path
            print(f"[INFO] Kaggle ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤: {raw_data_root}")
            
            # ì‹¤ì œ í´ë” êµ¬ì¡° í™•ì¸ ë° ê²½ë¡œ ì¡°ì •
            path_obj = Path(raw_data_root)
            
            # ë§Œì•½ ë°”ë¡œ Training/Testing í´ë”ê°€ ìˆë‹¤ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            if (path_obj / "Training").exists() and (path_obj / "Testing").exists():
                print("[INFO] Training/Testing í´ë”ë¥¼ ì§ì ‘ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            # ë§Œì•½ í•˜ìœ„ í´ë”ì— Training/Testingì´ ìˆë‹¤ë©´ ê²½ë¡œ ì¡°ì •
            elif any((path_obj / subdir / "Training").exists() and (path_obj / subdir / "Testing").exists() 
                     for subdir in path_obj.iterdir() if subdir.is_dir()):
                for subdir in path_obj.iterdir():
                    if subdir.is_dir() and (subdir / "Training").exists() and (subdir / "Testing").exists():
                        raw_data_root = subdir
                        print(f"[INFO] í•˜ìœ„ í´ë”ì—ì„œ Training/Testingì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {raw_data_root}")
                        break
            else:
                print("[WARNING] Training/Testing í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
                print(f"[INFO] ë‹¤ìš´ë¡œë“œëœ í´ë” ë‚´ìš©ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤: {path_obj}")
        else:
            print("[WARNING] Kaggle ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ê²½ë¡œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # ê²½ë¡œë¥¼ Path ê°ì²´ë¡œ ë³€í™˜
    raw_data_root = Path(raw_data_root)
    processed_data_root = Path(processed_data_root)
    
    print(f"[INFO] ì›ë³¸ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ: {raw_data_root.absolute()}")
    print(f"[INFO] ì²˜ë¦¬ëœ ë°ì´í„° ë£¨íŠ¸ ê²½ë¡œ: {processed_data_root.absolute()}")
    
    # Trainingê³¼ Testing ë°ì´í„° ëª¨ë‘ ì²˜ë¦¬
    datasets = ["Training", "Testing"]
    
    for dataset in datasets:
        print(f"\n[INFO] {dataset} ë°ì´í„°ì…‹ ì²˜ë¦¬ ì‹œì‘...")
        
        # ê²½ë¡œ ì„¤ì •
        raw_data_path = raw_data_root / dataset
        processed_data_path = processed_data_root / dataset
        
        notumor_path = processed_data_path / "notumor"
        tumor_path = processed_data_path / "tumor"
        
        # ì›ë³¸ í´ë” í™•ì¸
        if not raw_data_path.exists():
            print(f"[WARNING] {dataset} ì›ë³¸ ë°ì´í„° í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {raw_data_path}")
            continue
        
        # processed_data í´ë” ìƒì„±
        processed_data_path.mkdir(parents=True, exist_ok=True)
        
        # ê¸°ì¡´ í´ë”ê°€ ìˆë‹¤ë©´ ì‚­ì œ í›„ ì¬ìƒì„±
        if notumor_path.exists():
            shutil.rmtree(notumor_path)
        if tumor_path.exists():
            shutil.rmtree(tumor_path)
        
        notumor_path.mkdir()
        tumor_path.mkdir()
        
        print(f"[INFO] {dataset} ì´ì§„ë¶„ë¥˜ ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘...")
        print(f"[INFO] ì›ë³¸ ê²½ë¡œ: {raw_data_path}")
        print(f"[INFO] ì²˜ë¦¬ëœ ë°ì´í„° ê²½ë¡œ: {processed_data_path}")
        
        # íŒŒì¼ ì¹´ìš´í„°
        notumor_count = 0
        tumor_count = 0
        
        # notumor -> notumor í´ë”ë¡œ ë³µì‚¬
        source_notumor_path = raw_data_path / "notumor"
        if source_notumor_path.exists():
            for img_file in source_notumor_path.glob("*"):
                if img_file.is_file() and img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                    dest_file = notumor_path / img_file.name
                    shutil.copy2(img_file, dest_file)
                    notumor_count += 1
            print(f"[INFO] {dataset} Notumor ì´ë¯¸ì§€ {notumor_count}ê°œë¥¼ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"[WARNING] {dataset} Notumor í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {source_notumor_path}")
        
        # glioma, meningioma, pituitary -> tumor í´ë”ë¡œ ë³µì‚¬
        tumor_types = ["glioma", "meningioma", "pituitary"]
        
        for tumor_type in tumor_types:
            tumor_type_path = raw_data_path / tumor_type
            if tumor_type_path.exists():
                type_count = 0
                for img_file in tumor_type_path.glob("*"):
                    if img_file.is_file() and img_file.suffix.lower() in ['.jpg', '.jpeg', '.png', '.bmp']:
                        # íŒŒì¼ëª…ì— ì¢…ì–‘ íƒ€ì…ì„ prefixë¡œ ì¶”ê°€í•˜ì—¬ êµ¬ë¶„
                        dest_file = tumor_path / f"{tumor_type}_{img_file.name}"
                        shutil.copy2(img_file, dest_file)
                        type_count += 1
                        tumor_count += 1
                print(f"[INFO] {dataset} {tumor_type} ì´ë¯¸ì§€ {type_count}ê°œë¥¼ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"[WARNING] {dataset} {tumor_type} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {tumor_type_path}")
        
        print(f"\n[SUCCESS] {dataset} ì´ì§„ë¶„ë¥˜ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print(f"[INFO] {dataset} Notumor: {notumor_count}ê°œ")
        print(f"[INFO] {dataset} Tumor: {tumor_count}ê°œ")
        print(f"[INFO] {dataset} ì´ {notumor_count + tumor_count}ê°œ ì´ë¯¸ì§€ê°€ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    print(f"\n[SUCCESS] ëª¨ë“  ë°ì´í„°ì…‹ ì²˜ë¦¬ ì™„ë£Œ!")
    return True

if __name__ == "__main__":
    ## ì„ íƒ1, 2 ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ í›„ ë‚˜ë¨¸ì§€ëŠ” ì£¼ì„ ì²˜ë¦¬ í›„ ì‹¤í–‰

    #(ì„ íƒ1): Colab ì‹¤í–‰ ì‹œ ìë™ ë‹¤ìš´ë¡œë“œ ì§€ì›
    # processed_root = Path("/content/drive/MyDrive/Adversarial_AI/processed_data")   ## ê²½ë¡œ ìˆ˜ì • ê°€ëŠ¥
    # processed_root.parent.mkdir(parents=True, exist_ok=True)
    # create_binary_classification_dataset(
    #     processed_data_root=processed_root,
    #     download_from_kaggle=True
    # )

    # (ì„ íƒ2): ë¡œì»¬ ì‹¤í–‰ ì‹œ ê¸°ë³¸ê°’ ì‚¬ìš© ë° kaggle ìë™ ë‹¤ìš´ë¡œë“œ ì§€ì›
    create_binary_classification_dataset(download_from_kaggle=True)
    
# (ì„ íƒ) Colab ì‹¤í–‰ í›„ ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì •ìƒ ì €ì¥ ì—¬ë¶€ í™•ì¸ ê°€ëŠ¥
# !ls -la "/content/drive/MyDrive/Adversarial_AI" || echo "Adversarial_AI ì—†ìŒ"
# !ls -la "/content/drive/MyDrive/Adversarial_AI/processed_data" || echo "processed_data ì—†ìŒ"
# !ls -la "/content/drive/MyDrive/Adversarial_AI/processed_data/Training" || echo "Training ì—†ìŒ"