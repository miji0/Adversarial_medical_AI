# -*- coding: utf-8 -*-
"""Copy of jsma_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g-Ihy1kneVC5SUhfZ2qa9kDp7VTbdRdl
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Adversarial_AI/Adversarial_AI

!python adv_utils.py
!python preprocess2_ResNet50.py
!python JSMA_Attack.py

"""

---

"""

# jsma_test.py
import os, sys, time, argparse, csv
from pathlib import Path
from typing import Dict

import numpy as np
import torch
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR

from adv_utils import (
    seed_everything, get_default_config, build_loaders, build_model,
    find_ckpt, load_checkpoint, collect_first_n_correct,
    summarize_jsma_metrics
)
from JSMA_Attack import jsma_attack
import sys

import os, sys, time, csv, argparse
from pathlib import Path
from typing import Dict

import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
from torch.optim.lr_scheduler import CosineAnnealingLR

DEFAULT_KS = [2, 5, 10]
THETA = 0.1
MAX_PIXELS_PCT = 0.05
RESTARTS = 3
TOPK_POOL = 2000
USE_ROI_MASK = False
NUM_SAMPLES = 100
OUT_DIR = Path("./attack_outputs/test02")

# =========================
# 유틸
# =========================
EPS_CM = 1e-12  # CMD 정규화 시 0 나눔 방지

def find_ckpt(out_dir: str | Path) -> Path:
    out_dir = Path(out_dir)
    for name in ["resnet50_binary_best.pth", "resnet50_binary_final.pth"]:
        p = out_dir / name
        if p.exists():
            return p
    raise FileNotFoundError(f"No checkpoint found in {out_dir}")

def _mean_median(x):
    arr = np.asarray(list(x), dtype=float)
    if arr.size == 0:
        return 0.0, 0.0
    return float(arr.mean()), float(np.median(arr))

def _tensor_to_img01(t: torch.Tensor) -> np.ndarray:
    """(1,3,H,W) 또는 (3,H,W) 텐서를 (H,W,3) np.float32 [0,1]로 변환/클램프"""
    if t.ndim == 4:
        t = t[0]
    arr = t.detach().cpu().permute(1, 2, 0).numpy().astype(np.float32)
    return np.clip(arr, 0.0, 1.0)

def _coerce_mask_2d_bool(mask, H, W, device, strict: bool = False):
    """ROI 마스크를 (H,W) bool로 강제 변환."""
    if mask is None:
        return None
    t = torch.as_tensor(mask, device=device)
    if t.ndim == 2 and t.shape == (H, W):
        return t.bool()
    if t.ndim == 3:
        if t.shape[0] == 1 and t.shape[1:] == (H, W):
            return t.squeeze(0).bool()
        if t.shape[-1] == 1 and t.shape[:2] == (H, W):
            return t.squeeze(-1).bool()
        if t.numel() == H * W:
            return t.reshape(H, W).bool()
    if t.ndim == 1:
        if t.shape[0] == H:
            return t[:, None].expand(H, W).bool()
        if t.shape[0] == W:
            return t[None, :].expand(H, W).bool()
        if t.numel() == H * W:
            return t.reshape(H, W).bool()
    if t.numel() == H * W:
        return t.reshape(H, W).bool()
    msg = f"allowed_masks must be (H,W)/(B,H,W) or broadcastable; got shape={tuple(t.shape)}"
    if strict:
        raise ValueError(msg)
    else:
        print(f"[WARN] {msg}. ROI 마스크를 사용하지 않습니다.")
        return None

def _save_3x3_panel_magnitude(
    x: torch.Tensor,
    adv_by_k: Dict[int, torch.Tensor],
    succ_by_k: Dict[int, bool],
    ks,
    save_path: Path,
):
    """
    3x3 패널 저장 (열: k 리스트 / 행: original, adversarial, perturbation(‖Δ‖))
    - perturbation은 채널 방향 L2 크기: ‖Δ‖ = sqrt((ΔR)^2+(ΔG)^2+(ΔB)^2)
    - 공통 스케일은 전체 k의 99.5퍼센타일로 정규화
    """
    if len(ks) != 3:
        print(f"[WARN] ks length is {len(ks)}; only first 3 will be shown.")
        ks = ks[:3]

    def _to_img01(t: torch.Tensor) -> np.ndarray:
        if t.ndim == 4:
            t = t[0]
        arr = t.detach().cpu().permute(1, 2, 0).numpy().astype(np.float32)
        return np.clip(arr, 0.0, 1.0)

    x0 = _to_img01(x)
    mags = []
    for k in ks:
        xa = _to_img01(adv_by_k[k])
        d = xa - x0
        mag = np.sqrt(np.sum(d * d, axis=2))
        mags.append(mag)
    vmax = np.percentile(np.concatenate([m.ravel() for m in mags]), 99.5) if any([np.any(m>0) for m in mags]) else 1.0

    fig = plt.figure(figsize=(12, 12))
    last_im = None
    for c, k in enumerate(ks, start=1):
        xa = _to_img01(adv_by_k[k])
        d = xa - x0
        mag = np.sqrt(np.sum(d * d, axis=2))
        mag_norm = np.clip(mag / (vmax + 1e-12), 0.0, 1.0)

        ax = plt.subplot(3, 3, c); ax.imshow(x0, vmin=0, vmax=1); ax.set_title("original"); ax.axis("off")
        ax = plt.subplot(3, 3, 3 + c); ax.imshow(xa, vmin=0, vmax=1)
        mark = "✓" if succ_by_k.get(k, False) else "✗"; ax.set_title(f"adv (k={k}) {mark}"); ax.axis("off")
        ax = plt.subplot(3, 3, 6 + c); last_im = ax.imshow(mag_norm, cmap="magma", vmin=0.0, vmax=1.0)
        ax.set_title("perturbation ‖Δ‖"); ax.axis("off")

    cbar_ax = fig.add_axes([0.92, 0.12, 0.015, 0.76])
    if last_im is not None:
        fig.colorbar(last_im, cax=cbar_ax)
    plt.tight_layout(rect=[0.03, 0.03, 0.90, 0.97])
    save_path.parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(save_path, dpi=220, bbox_inches="tight"); plt.close(fig)
    print(f"[VIS] Saved 3x3 panel: {save_path}")

# --------- 로그잇 기반 CMD 헬퍼 ----------
@torch.no_grad()
def _predict_logits(model, x):
    """x: (B,3,H,W) -> logits: (B,C)"""
    return model(x)

def _logit_margin_from_logits(logits: torch.Tensor, y_idx: int) -> float:
    """margin = logit[y] - max_{j!=y} logit[j]"""
    y = int(y_idx)
    C = logits.size(1)
    correct = logits[0, y]
    if C == 1:
        return float(correct.item())
    if y == 0:
        max_other = logits[0, 1:].max()
    elif y == C - 1:
        max_other = logits[0, :-1].max()
    else:
        max_other = torch.max(logits[0, :y].max(), logits[0, y+1:].max())
    return float((correct - max_other).item())

# =========================
# 성능 강화 JSMA (마진 + 모멘텀 + 동적 k + 최적화)
# =========================
def _margin_and_grad(model, x, y_idx):
    """
    margin(x) = logit[y] - max_{j!=y} logit[j]
    반환: margin(float), grad(d margin / d x), pred_lbl(int)
    """
    with torch.enable_grad():
        x = x.clone().detach().requires_grad_(True)
        logits = model(x)  # 한 번만 수행
        y = int(y_idx.item() if torch.is_tensor(y_idx) else y_idx)

        c = logits.size(1)
        if c == 2:
            j_star = 1 - y
        else:
            tmp = logits[0].clone()
            tmp[y] = -1e9
            j_star = int(tmp.argmax().item())

        margin_t = logits[0, y] - logits[0, j_star]
        grad = torch.autograd.grad(margin_t, x, retain_graph=False, create_graph=False, allow_unused=False)[0]

    pred_lbl = int(logits.detach().argmax(dim=1).item())
    return float(margin_t.item()), grad.detach(), pred_lbl

def jsma_attack_margin_mom(
    model,
    x,                # (1,3,H,W) in [0,1]
    y_true,           # (1,)
    theta=0.08,       # 기본 스텝
    max_pixels_percentage=0.05,   # 변경 허용(공간 픽셀 기준)
    k_small=2,        # 초기 k
    k_big=12,         # 정체 시 k 확대
    patience=3,       # margin 개선 정체 허용 스텝
    momentum=0.75,    # gradient EMA 모멘텀
    restarts=4,       # 재시도 횟수
    topk_pool=5000,   # 후보 풀
    allowed_masks=None,   # (H,W) bool
    clamp=(0.0, 1.0),
    early_success=True
):
    """
    반환: x_adv(1,3,H,W), changed_spatial(int), l1_total(float), success(0/1 tensor)
    """
    device = x.device
    _, C, H, W = x.shape
    budget = int(max_pixels_percentage * H * W)
    best = None  # (success, changed, -final_margin, x_adv, l1)

    if allowed_masks is not None:
        roi = allowed_masks.bool().to(device)
    else:
        roi = torch.ones((H, W), dtype=torch.bool, device=device)

    for _ in range(restarts):
        x_adv = x.clone().detach()
        v = torch.zeros_like(x_adv)           # momentum buffer
        changed_mask = torch.zeros((H, W), dtype=torch.bool, device=device)
        last_margins = []
        changed_spatial = 0

        step_theta = theta
        k = k_small
        success = False

        while changed_spatial < budget:
            # 현재 margin / grad / pred (중복 forward 제거)
            margin, g, pred_lbl = _margin_and_grad(model, x_adv, y_true)
            last_margins.append(margin)
            if len(last_margins) > patience + 1:
                last_margins.pop(0)

            # 이미 성공?
            if early_success and pred_lbl != int(y_true.item()):
                success = True
                break

            # momentum 업데이트 (EMA)
            v = momentum * v + (1.0 - momentum) * g

            # saliency(공간) = Σ_c |v_c|
            sal = v.abs().sum(dim=1, keepdim=False)[0]  # (H,W)

            # 업데이트 불가 위치 마스킹
            eligible = roi & (~changed_mask)
            with torch.no_grad():
                sign_v = v.sign()[0]  # (3,H,W)
                up_block   = (sign_v > 0) & (x_adv[0] <= clamp[0] + 1e-6)
                down_block = (sign_v < 0) & (x_adv[0] >= clamp[1] - 1e-6)
                blocked = up_block.any(dim=0) | down_block.any(dim=0)
                eligible = eligible & (~blocked)

            if not eligible.any():
                break

            # 마스킹 + topk (커널 호출 수↓)
            sal_masked = sal.masked_fill(~eligible, float('-inf'))
            flat = sal_masked.view(-1)
            k_pool = min(topk_pool, flat.numel())
            idx_pool = flat.topk(k_pool, largest=True).indices
            if idx_pool.numel() == 0 or torch.isneginf(flat[idx_pool[0]]):
                break

            k_eff = min(k, idx_pool.numel(), budget - changed_spatial)
            idx_pick = idx_pool[:k_eff]
            ys = (idx_pick // W).long()
            xs = (idx_pick %  W).long()

            # 벡터화 업데이트 + 누적 카운트
            with torch.no_grad():
                upd = step_theta * v[0, :, ys, xs].sign()
                x_adv[0, :, ys, xs] = (x_adv[0, :, ys, xs] - upd).clamp_(clamp[0], clamp[1])
                changed_mask[ys, xs] = True
                changed_spatial += k_eff

            # margin 정체시 k/θ 조절
            if len(last_margins) >= patience + 1:
                if last_margins[0] - last_margins[-1] < 1e-4:  # 개선 거의 없음
                    k = min(k_big, k * 2)
                    step_theta = min(step_theta * 1.25, 0.2)
                else:
                    k = max(k_small, k // 2)
                    step_theta = max(step_theta * 0.95, theta * 0.5)

        # 결과 집계
        with torch.no_grad():
            diff = (x_adv - x).abs()
            l1_total = float(diff.sum().item())
            # 최종 성공 판정
            pred_final = _predict_logits(model, x_adv).argmax(dim=1)
            success = success or (int(pred_final.item()) != int(y_true.item()))
            # 최종 margin(작을수록 좋음)
            fin_margin, _, _ = _margin_and_grad(model, x_adv, y_true)

        cand = (success, changed_spatial, -fin_margin, x_adv.detach(), l1_total)
        if best is None:
            best = cand
        else:
            if (cand[0] and not best[0]) \
               or (cand[0] and best[0] and cand[1] < best[1]) \
               or (cand[0] == best[0] and cand[1] == best[1] and cand[2] > best[2]):
                best = cand

    success, changed_spatial, _neg_margin, x_best, l1_total = best
    return x_best, torch.tensor(changed_spatial), torch.tensor(l1_total, dtype=torch.float32), torch.tensor(1 if success else 0)

# =========================
# 메인
# =========================
def main():
    parser = argparse.ArgumentParser(description="JSMA (margin+momentum, optimized) on N random correct test images")
    parser.add_argument("--ks", type=str, default="2,5,10", help="comma-separated k list (추천 3개)")
    parser.add_argument("--theta", type=float, default=THETA)
    parser.add_argument("--max_pct", type=float, default=MAX_PIXELS_PCT)
    parser.add_argument("--restarts", type=int, default=RESTARTS)
    parser.add_argument("--topk_pool", type=int, default=TOPK_POOL)
    parser.add_argument("--use_roi", action="store_true", default=USE_ROI_MASK)
    parser.add_argument("--num", type=int, default=NUM_SAMPLES, help="random correctly-classified samples")
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--out_dir", type=str, default=str(OUT_DIR))
    # 성능/출력 옵션
    parser.add_argument("--mom", type=float, default=0.75, help="momentum (0.7~0.85 권장)")
    parser.add_argument("--patience", type=int, default=3, help="margin 정체 허용 스텝")
    parser.add_argument("--kbig_min", type=int, default=12, help="정체 시 k 상한 최소값")
    parser.add_argument("--save_every", type=int, default=1, help="패널 저장 간격 (1=모두)")
    parser.add_argument("--save_success_only", action="store_true", help="성공 샘플만 패널 저장")

    args = parser.parse_args([]) if 'ipykernel' in sys.modules else parser.parse_args()
    ks = [int(v) for v in args.ks.split(",")]

    # === 환경/데이터/모델 ===
    CFG = get_default_config()
    seed_everything(args.seed if args.seed is not None else CFG["seed"])
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    train_loader, val_loader, test_loader, class_names = build_loaders(
        CFG["train_dir"], CFG["test_dir"],
        batch_size=CFG["batch_size"], val_ratio=CFG["val_ratio"], num_workers=CFG["num_workers"]
    )

    model, optimizer, _ = build_model(num_classes=len(class_names), lr=CFG["lr"], weight_decay=CFG["weight_decay"])
    model = model.to(device)
    scheduler = CosineAnnealingLR(optimizer, T_max=CFG["epochs"])
    ckpt_path = find_ckpt(CFG["out_dir"])
    load_checkpoint(str(ckpt_path), model, optimizer, scheduler, device)

    # 실행 시간 최적화: 파라미터 grad 끄기 + cudnn 튜닝
    for p in model.parameters():
        p.requires_grad_(False)
    model.eval()
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True

    print(f"[INFO] Loaded checkpoint: {ckpt_path}")

    out_dir = Path(args.out_dir); out_dir.mkdir(parents=True, exist_ok=True)
    panels_dir = out_dir / "panels"; panels_dir.mkdir(parents=True, exist_ok=True)

    # === 정분류된 N장 무작위 수집 ===
    xN, yN, mN = collect_first_n_correct(
        model=model, loader=test_loader, n=args.num, device=device,
        random_pick=True, seed=args.seed
    )
    N = xN.size(0); H, W = xN.shape[-2], xN.shape[-1]
    print(f"[INFO] Collected {N} correctly classified samples (random).")
    print(f"[DEBUG] xN={tuple(xN.shape)}, yN={tuple(yN.shape)}, mN={None if mN is None else tuple(mN.shape)}")

    # === 집계 버퍼 ===
    succ_by_k_all   = {k: [] for k in ks}
    changed_by_k_all= {k: [] for k in ks}
    l1_by_k_all     = {k: [] for k in ks}
    time_by_k_all   = {k: [] for k in ks}
    cmd_by_k_all    = {k: [] for k in ks}
    cmdrel_by_k_all = {k: [] for k in ks}
    per_sample_rows = []

    t_total0 = time.perf_counter()

    # === 본 루프 ===
    for i in range(N):
        xi = xN[i:i+1].to(device)   # (1,3,H,W)
        yi = yN[i:i+1].to(device)   # (1,)
        mi = None if mN is None else _coerce_mask_2d_bool(mN[i], H, W, device)

        # clean logits/margin은 샘플마다 한 번만
        with torch.no_grad():
            logits_clean = _predict_logits(model, xi)
        y_idx = int(yi.item())
        m_clean = _logit_margin_from_logits(logits_clean, y_idx)

        sample_adv_by_k: Dict[int, torch.Tensor] = {}
        sample_succ_by_k: Dict[int, bool] = {}

        for k in ks:
            t0 = time.perf_counter()
            x_adv, changed_arr, l1_arr, success_arr = jsma_attack_margin_mom(
                model=model,
                x=xi,
                y_true=yi,
                theta=args.theta,                     # 0.06~0.10 권장
                max_pixels_percentage=args.max_pct,   # 0.05 기본
                k_small=min(k, 4),
                k_big=max(args.kbig_min, k*2),
                patience=args.patience,
                momentum=args.mom,
                restarts=max(4, args.restarts),       # 4~6 권장
                topk_pool=max(4000, args.topk_pool),  # 5k~10k 권장
                allowed_masks=(mi if args.use_roi else None),
                clamp=(0.0, 1.0),
                early_success=True
            )
            elapsed = time.perf_counter() - t0

            ch = int(changed_arr.item())
            l1 = float(l1_arr.item())
            succ = bool(success_arr.item())

            # --- CMD 계산 (logit 기반) ---
            with torch.no_grad():
                logits_adv = _predict_logits(model, x_adv)
            m_adv   = _logit_margin_from_logits(logits_adv, y_idx)
            cmd     = m_clean - m_adv
            cmd_rel = cmd / (abs(m_clean) + EPS_CM)

            # 집계
            succ_by_k_all[k].append(succ)
            changed_by_k_all[k].append(ch)
            l1_by_k_all[k].append(l1)
            time_by_k_all[k].append(elapsed)
            cmd_by_k_all[k].append(cmd)
            cmdrel_by_k_all[k].append(cmd_rel)

            per_sample_rows.append({
                "index": i, "k": k, "changed": ch, "L1": l1,
                "success": int(succ), "time_sec": elapsed,
                "logit_margin_clean": m_clean, "logit_margin_adv": m_adv,
                "cmd": cmd, "cmd_rel": cmd_rel
            })

            sample_adv_by_k[k] = x_adv.detach().cpu()
            sample_succ_by_k[k] = succ

        # 패널 저장(옵션)
        save_flag = ((i % max(1, args.save_every)) == 0)
        if args.save_success_only:
            save_flag = save_flag and any(sample_succ_by_k.values())
        if save_flag:
            panel_path = panels_dir / f"sample_{i:03d}.png"
            _save_3x3_panel_magnitude(x=xN[i:i+1], adv_by_k=sample_adv_by_k,
                                      succ_by_k=sample_succ_by_k, ks=ks, save_path=panel_path)

        if (i + 1) % 10 == 0 or (i + 1) == N:
            print(f"[PROGRESS] saved panels & results for {i+1}/{N}")

    total_elapsed = time.perf_counter() - t_total0
    print(f"[TIME] Total elapsed for {N} samples: {total_elapsed:.2f}s")

    # ==== 이미지 단위 요약 (성공한 k 중 '가장 빠른' 결과) ====
    best_per_image = {}
    for i in range(N):
        cands = [r for r in per_sample_rows if (r["index"] == i and r["success"] == 1)]
        if len(cands) > 0:
            best = min(cands, key=lambda r: r["time_sec"])
            best_per_image[i] = {
                "success": 1,
                "changed": best["changed"],
                "L1": best["L1"],
                "time_sec": best["time_sec"],
                "cmd": best["cmd"],
                "cmd_rel": best["cmd_rel"],
            }
        else:
            best_per_image[i] = {"success": 0, "changed": 0, "L1": 0.0, "time_sec": 0.0, "cmd": 0.0, "cmd_rel": 0.0}

    img_success_flags = np.array([v["success"] for v in best_per_image.values()], dtype=np.float32)
    ASR_img = float(img_success_flags.mean()) if len(img_success_flags) > 0 else 0.0
    succ_changed = [v["changed"] for v in best_per_image.values() if v["success"] == 1]
    succ_times   = [v["time_sec"] for v in best_per_image.values() if v["success"] == 1]
    succ_cmd     = [v["cmd"] for v in best_per_image.values() if v["success"] == 1]
    succ_cmdrel  = [v["cmd_rel"] for v in best_per_image.values() if v["success"] == 1]

    Mean_Changed_success = float(np.mean(succ_changed)) if len(succ_changed) > 0 else 0.0
    Mean_Time_success    = float(np.mean(succ_times))   if len(succ_times)   > 0 else 0.0
    Mean_CMD_success     = float(np.mean(succ_cmd))     if len(succ_cmd)     > 0 else 0.0
    Mean_CMDrel_success  = float(np.mean(succ_cmdrel))  if len(succ_cmdrel)  > 0 else 0.0

    print("\n[IMAGE-LEVEL SUMMARY]")
    print(f"  - 제작 성공률(이미지 단위): {ASR_img*100:.2f}%  ({int(round(ASR_img*N))}/{N})")
    print(f"  - (성공 샘플 기준) 평균 조작 픽셀 수: {Mean_Changed_success:.2f}")
    print(f"  - (성공 샘플 기준) 평균 시간(초)   : {Mean_Time_success:.3f}s")
    print(f"  - (성공 샘플 기준) 평균 CMD(logit) : {Mean_CMD_success:.4f}")
    print(f"  - (성공 샘플 기준) 평균 CMD_rel    : {Mean_CMDrel_success:.4f}")

    with open(out_dir / "summary_image_level.txt", "w", encoding="utf-8") as f:
        f.write(f"ASR_image = {ASR_img:.4f}  ({int(round(ASR_img*N))}/{N})\n")
        f.write(f"Mean_Changed_success = {Mean_Changed_success:.4f}\n")
        f.write(f"Mean_Time_success = {Mean_Time_success:.4f}\n")
        f.write(f"Mean_CMD_success = {Mean_CMD_success:.6f}\n")
        f.write(f"Mean_CMDrel_success = {Mean_CMDrel_success:.6f}\n")

    # ==== k별 요약 및 CSV 저장 ====
    rows = []
    for k in ks:
        metrics = summarize_jsma_metrics(
            success_arr=succ_by_k_all[k],
            changed_arr=changed_by_k_all[k],
            l1_arr=l1_by_k_all[k],
            image_hw=(H, W),
            times_sec=time_by_k_all[k],
            print_summary=True,
        )
        cmd_mean, cmd_med         = _mean_median(cmd_by_k_all[k])
        cmdrel_mean, cmdrel_med   = _mean_median(cmdrel_by_k_all[k])

        print(f"  · CMD_mean(logit)   : {cmd_mean:.6f} (median {cmd_med:.6f})")
        print(f"  · CMD_rel_mean      : {cmdrel_mean:.6f} (median {cmdrel_med:.6f})")

        rows.append({
            "k": k,
            "ASR": metrics["ASR"],
            "Mean_Changed": metrics["Mean_Changed"],
            "Median_Changed": metrics["Median_Changed"],
            "Mean_Changed_Pct": metrics.get("Mean_Changed_Pct", None),
            "Median_Changed_Pct": metrics.get("Median_Changed_Pct", None),
            "Mean_L1": metrics["Mean_L1"],
            "Median_L1": metrics["Median_L1"],
            "Mean_Delta_per_ModifiedPixel": metrics["Mean_Delta_per_ModifiedPixel"],
            "Mean_Time_sec": metrics.get("Mean_Time_sec", None),
            "Median_Time_sec": metrics.get("Median_Time_sec", None),
            "CMD_mean": cmd_mean, "CMD_median": cmd_med,
            "CMDrel_mean": cmdrel_mean, "CMDrel_median": cmdrel_med,
        })

    csv_path = out_dir / "randomN_summary.csv"
    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))
        writer.writeheader(); writer.writerows(rows)
    print(f"[SAVE] Summary CSV: {csv_path}")

    csv_ind_path = out_dir / "per_sample_results.csv"
    with open(csv_ind_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=list(per_sample_rows[0].keys()))
        writer.writeheader(); writer.writerows(per_sample_rows)
    print(f"[SAVE] Per-sample CSV: {csv_ind_path}")

    with open(out_dir / "summary.txt", "w", encoding="utf-8") as f:
        f.write(f"NumSamples={N}, HxW={H}x{W}, total_elapsed_sec={total_elapsed:.2f}\n")
        for row in rows:
            f.write(
                f"k={row['k']} | ASR={row['ASR']:.4f} | "
                f"MeanChanged={row['Mean_Changed']:.2f} ({row['Mean_Changed_Pct']:.2f}%) | "
                f"MedianChanged={row['Median_Changed']:.2f} ({row['Median_Changed_Pct']:.2f}%) | "
                f"MeanL1={row['Mean_L1']:.6f} | MedianL1={row['Median_L1']:.6f} | "
                f"MeanΔ/px={row['Mean_Delta_per_ModifiedPixel']:.6f} | "
                f"MeanTime={row['Mean_Time_sec']:.3f}s | MedianTime={row['Median_Time_sec']:.3f}s | "
                f"CMD_mean={row['CMD_mean']:.6f} | CMD_median={row['CMD_median']:.6f} | "
                f"CMDrel_mean={row['CMDrel_mean']:.6f} | CMDrel_median={row['CMDrel_median']:.6f}\n"
            )

    print(f"[DONE] Panels  → {panels_dir.resolve()}")
    print(f"[DONE] Outputs → {out_dir.resolve()}")

if __name__ == "__main__":
    main()